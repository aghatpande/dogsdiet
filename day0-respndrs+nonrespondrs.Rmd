---
title: "day0-respndrs+nonrespndrs"
author: "ASG"
date: "5/8/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, libraries}
library(readr)
library(tidyverse)
```

## Introduction

The experimental arm of the study included many (29 per paper) dogs. Of these, some dogs responded and others didn't repond well to diet intervention. In order to understand if these dogs with clinical IBD had significantly different microbiomes before the dietary manipulation we need to compare their microbiomes to those with the healthy control dogs. 

```{r, filtering runinfo for day0-respndrs+nonrespndrs}
day0Runinfo <- filtered_runinfo %>% filter(agrepl("C166_dd_Day0_", SampleName))
```

## Filtering out technical replicates on the basis of number of reads

The authors mention that their 'experimental' cohort comprised 29 dogs. In this data we have 49 samples. Examination of the 'day0Runinfo' table (sort by SampleName in RStudio to make for easier inspection) shows replicates from very likely the same subject. For example, in the sorted day0Runinfo table the first three rows with SampleNames C166_01_Day0_10815, C166_01_Day0_10943, C166_01_Day0_11535 differ only by their library names (last number after the '_'). These three entries show very different read counts : 1641, 21711, 51325 respectively. Similarly other samples show a similar pattern. 

Our tactic is to filter out by the dogIDs (middle 2 numbers in SampleName) and take the the data with the maximum read counts, assuming the read count reflects a sequencing run with the best conditions.

```{r, filtering tech replicates based on max read counts from each dog}
day0spots <- day0Runinfo %>% mutate(pairedReads = as.numeric(spots_with_mates)) %>% select(Run,SampleName,pairedReads)
day0Runs<-day0spots %>% separate(SampleName,c("Name","dogID", "day","libID")) %>% select(dogID, Run, pairedReads) %>% group_by(dogID) %>% filter(pairedReads == max(pairedReads))
```



## Generating a manifest file that Qiime2 needs for importing data

Note: the allfastqs_manifest object needs the first column to be 'sampleid' not 'Run' or 'sample-id' for the code below to work! allfastqs_manifest is generated by the Rnotebook code with the 'sampleid' column name inserted using the Numbers program initially!

```{r, generating the day0 manifest file}
day0_manifest <- allfastqs_manifest %>% filter (sampleid %in% day0Runs$Run)
day0_manifest %>% write_tsv("day0Manifest.tsv")
```

The .tsv file needs to be a tab separated *text* file for Qiime2 to import. This was done using the foll command at commmand line:

    cp day0Manifest.tsv day0Manifest
    
## 7. importing the day0 data into Qiime2

  *Note the fastq.gz files need to be in the PWD for this step*. The import was done using the foll command in the *Qiime2 conda environment*:

      qiime tools import --type 'SampleData[PairedEndSequencesWithQuality]'\
      --input-path day0Manifest\
      --output-path day0demux.qza\
      --input-format PairedEndFastqManifestPhred33V2\
      ;

The important parameters are as specified above for the data in SRA, which was already demuliplexed and sorted into per sample data (likely barcodes removed). The data was fastq format with Phred scores. We *assumed* that the Phred score is Phred33 based since Illumina moved from Phred64 a while ago (per Shilpa)

The data was successfully imported with the foll: message from Qiime2

  Imported day0Manifest as PairedEndFastqManifestPhred33V2 to day0demux.qza

    
## 8. summarizing and visualizing the imported demultiplexed reads data

Following along the 'moving pictures' tutorial in Qiime 2 docs, we then generate a summary of the demulitplexed data in the *Qiime2 conda environment* and the /Users/asgghar/edu/metagenomics/beiting directory:

        qiime demux summarize --i-data day0demux.qza\
                              --o-visualization day0demux.qzv\
                              ;
            
  Qiime2 says: Saved Visualization to: day0demux.qzv

  The visualization is viewed using the command below in the same directory and environment:

        qiime tools view day0demux.qzv

  *The UPenn team used an average Phred score of 20 for each sample and removed sequences >256 nt and < 250 nt in length per the paper*
  
## 9. picking ASVs (amplicon sequence variants aka zero noise OTUs) using dada2 method
  DADA2 is a pipeline for detecting and correcting (correcting sequencing, PCR errors, removing PCR generated chimeric sequences where possible) Illumina amplicon sequence data. As implemented in the q2-dada2 plugin, this quality control process will additionally filter any phiX reads (commonly present in marker gene Illumina sequence data) that are identified in the sequencing data, and will filter chimeric sequences. It will also merge paired reads. For details see foll references in the ~/metagenomics subdirectory:
  
  *DADA2-paper-nature-methods2016.pdf*. Also see *comparision-of-metagenomic-methods-2020.pdf* in same directory for a comparison of 6 diff methods and this paper
  claims the DADA2 method is one of the best at what it does. 
       
       qiime dada2 denoise-paired \
        --i-demultiplexed-seqs day0demux.qza \
        --p-trim-left-f 0 \
        --p-trim-left-r 0 \
        --p-trunc-len-f 250 \
        --p-trunc-len-r 250 \
        --o-representative-sequences day0-rep-seqs.qza \
        --o-table day0-table.qza \
        --o-denoising-stats day0-stats.qza \
        ;
        
Qiime2 produced the output with the foll message:
Saved FeatureTable[Frequency] to: day0-table.qza
Saved FeatureData[Sequence] to: day0-rep-seqs.qza
Saved SampleData[DADA2Stats] to: day0-stats.qza


## 10. Visualizing the dada2 output
        
        qiime metadata tabulate \
          --m-input-file day0-stats.qza \
          --o-visualization day0-stats.qzv \
         ;
  
Qiime2 produced the output with the mesg:
Saved Visualization to: day0-stats.qzv

## 11. Next step below requires a file containing metadata about the samples

  To generate a file called "day0-sample-metadata.tsv", we will use the previously created tibble: day0Runinfo and day0Runs (not using day0Runinfo directly since we filtered out technical replicates present in the day0Runinfo file)

```{r}
day0metadata <- day0Runinfo %>% select ("Run", "spots_with_mates", "Experiment", "LibraryName","Sample", "SampleName")
day0metadata <- day0metadata %>% mutate("sampleid" = day0metadata$Run, "category" = 'CEdogsDay0')
day0metadata <- day0metadata %>% filter(sampleid %in% day0Runs$Run)
day0metadata <- day0metadata %>% select("sampleid", "spots_with_mates", "Experiment", "LibraryName", "Sample","SampleName", "category")
day0metadata %>% write_tsv("day0-sample-metadata.tsv")
```
  
  
  

